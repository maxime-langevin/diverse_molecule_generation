{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assay and run directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_name = \"/common/workdir/diverse_molecule_generation/datasets/drd2_filtered.csv\"\n",
    "rundir = \"/common/workdir/diverse_molecule_generation/results/drd2_filtered_0.45_threshold/lstm_hc/drd2_filtered/\"\n",
    "pca_components = 50\n",
    "kmeans = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results/test/lstm_hc/CHEMBL3888429_cleaned/ecfp4_range_physchem_maxsim_ecfp6/2022-03-17_13:33:05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.decomposition import PCA\n",
    "from utils import data_split, ClusterFps, ecfp4, find_cluster, max_tanimoto_similarity, indexes_identical_fps, average_tanimoto_similarity, tanimoto_similarities, calculateScore, Descriptors, quantitative_analysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from rdkit.Chem.rdMolDescriptors import CalcTPSA\n",
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from rdkit.Chem.Crippen import MolLogP, MolMR\n",
    "\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 35}\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 35,\n",
    "    'text.usetex': False,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test, smiles_test, activities_test, clf = data_split(assay_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ecfp4_range_physchem_range_ecfp4_counts_beta_ 0_threshold_0.7',\n",
       " 'ecfp4_range_physchem_range_ecfp4_counts_beta_ 1_threshold_0.7',\n",
       " 'ecfp4_range_physchem_range_ecfp4_counts_beta_ 10_threshold_0.7']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(rundir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/common/workdir/diverse_molecule_generation/results/drd2_filtered_0.45_threshold/lstm_hc/drd2_filtered/ecfp4_range_physchem_range_ecfp4_counts_beta_0_threshold_0.45'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-414b1948303c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrajectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrundir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrundir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'results.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/common/workdir/diverse_molecule_generation/results/drd2_filtered_0.45_threshold/lstm_hc/drd2_filtered/ecfp4_range_physchem_range_ecfp4_counts_beta_0_threshold_0.45'"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "smiles_list = []\n",
    "scores_list = []\n",
    "scores_trajectories = []\n",
    "\n",
    "l = os.listdir(rundir)\n",
    "l = [ 'ecfp4_range_physchem_range_ecfp4_counts_beta_0_threshold_0.45',\n",
    "     'ecfp4_range_physchem_range_ecfp4_counts_beta_1_threshold_0.45',\n",
    "     'ecfp4_range_physchem_range_ecfp4_counts_beta_10_threshold_0.45',\n",
    "     'ecfp4_range_physchem_range_ecfp4_counts_beta_100_threshold_0.45',\n",
    "     'ecfp4_range_physchem_range_ecfp4_counts_beta_1000_threshold_0.45']\n",
    "for directory in l:\n",
    "    smiles = []\n",
    "    scores = []\n",
    "    trajectories = []\n",
    "    for result_dir in os.listdir(os.path.join(rundir, directory)):\n",
    "        try:\n",
    "            with open(os.path.join(rundir, directory, result_dir, 'results.json'), 'r') as f:\n",
    "                results = json.load(f)\n",
    "                smiles.extend([row['smiles'] for row in results['statistics']][-1])\n",
    "                scores.extend([row['preds']['scores'] for row in results['statistics']][-1])\n",
    "                #trajectories.extend([np.array(row['preds']['Split1']) for row in results['statistics']])\n",
    "                average_trajectories = np.array([np.mean(row['preds']['scores']) for row in results['statistics']])\n",
    "        except:\n",
    "            pass\n",
    "    if len(smiles)>0:\n",
    "        runs.append(directory)\n",
    "        scores_trajectories.append(average_trajectories)\n",
    "        smiles_list.append(smiles)\n",
    "        scores_list.append(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actives = []\n",
    "inactives = []\n",
    "smiles_actives = []\n",
    "smiles_inactives = []\n",
    "\n",
    "for i, s in enumerate(smiles_test):\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    if float(activities_test[i])==1:\n",
    "        actives.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2))\n",
    "        smiles_actives.append(s)\n",
    "    else:\n",
    "        inactives.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2))\n",
    "        smiles_inactives.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(actives + inactives)\n",
    "#clustering = DBSCAN(eps=0.25, min_samples=1, metric='jaccard', p=1).fit(X)\n",
    "clustering = KMeans(n_clusters=5, random_state=0).fit(X)\n",
    "\n",
    "kmeans_clusters = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_clusters = ClusterFps(actives + inactives, cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = [cluster[0] for cluster in training_set_clusters]\n",
    "fp_list = actives + inactives\n",
    "centroids_fp = [fp_list[centroid] for centroid in centroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_active_as_array = []\n",
    "fps_active_as_bitv = []\n",
    "fps_inactive_as_array = []\n",
    "fps_inactive_as_bitv = []\n",
    "fps_generated_as_array = []\n",
    "fps_generated_as_bitv = []\n",
    "\n",
    "for s in smiles_actives:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    fps_active_as_array.append(np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)))\n",
    "    fps_active_as_bitv.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2))\n",
    "    \n",
    "for s in smiles_inactives:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    fps_inactive_as_array.append(np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)))\n",
    "    fps_inactive_as_bitv.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2))\n",
    "    \n",
    "for i, run in enumerate(runs):\n",
    "    smiles_generated = smiles_list[i]\n",
    "    curr_fps_generated_as_array = []\n",
    "    curr_fps_generated_as_bv = []\n",
    "    for s in smiles_generated:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        curr_fps_generated_as_array.append(np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)))\n",
    "        curr_fps_generated_as_bv.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2))\n",
    "    fps_generated_as_array.append(curr_fps_generated_as_array)\n",
    "    fps_generated_as_bitv.append(curr_fps_generated_as_bv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(np.concatenate((fps_inactive_as_array,fps_inactive_as_array)))\n",
    "pca_active = pca.transform(fps_active_as_array)\n",
    "pca_inactive = pca.transform(fps_inactive_as_array)\n",
    "\n",
    "pca_generated = []\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    curr_fps_generated = fps_generated_as_array[i]\n",
    "    pca_generated.append(pca.transform(curr_fps_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin_ymin = np.amin(np.vstack([np.amin(p, axis=0) for p in pca_generated]), axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax_ymax = np.amax(np.vstack([np.amax(p, axis=0) for p in pca_generated]), axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lims = [xmin_ymin[0]] + [xmax_ymax[0]]\n",
    "y_lims = [xmin_ymin[1]] + [xmax_ymax[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runs_to_display = runs\n",
    "#runs_to_display = runs \n",
    "fig, axs = plt.subplots(figsize = (20, 20), nrows=max(1, math.ceil(len(runs_to_display)/3)) , ncols=3)\n",
    "fig.tight_layout(pad=1.5)\n",
    "\n",
    "for i, run in enumerate(runs_to_display):\n",
    "    index = runs.index(run)\n",
    "    pca_gen = pca_generated[index]\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.set_title(run.replace('_', ' '), fontsize=30)\n",
    "    ax.set_ylim(y_lims)\n",
    "    ax.set_xlim(x_lims)\n",
    "    ax.scatter(pca_gen[:, 0], pca_gen[:, 1], c='b', label = 'generated', alpha=1)\n",
    "    ax.scatter(pca_inactive[:, 0], pca_inactive[:, 1], c='r', label = 'inactives', alpha=0.25)\n",
    "    ax.scatter(pca_active[:, 0], pca_active[:, 1], c='g', label = 'actives', alpha=0.5)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=25)\n",
    "    if i==len(runs_to_display)-1: \n",
    "        ax.legend(loc='lower right',\n",
    "              ncol=1, fancybox=True, shadow=True, fontsize=30)\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/JAK2/PCA.png', dpi=300)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = []\n",
    "for s in smiles_test:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    fps.append(np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)))\n",
    "    \n",
    "plt.figure(figsize=(20, 20))\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(fps)\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown']\n",
    "\n",
    "validity = []\n",
    "\n",
    "    \n",
    "for s in smiles_test:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    fp = ecfp4([s])[0].reshape(1, -1)\n",
    "    prediction = clf.predict_proba(fp)[0, 1]\n",
    "    validity.append(prediction) \n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], label='dataset', alpha=0.25)\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    X_generated = []\n",
    "    for s in smiles_list[i]:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        X_generated.append(np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)))\n",
    "    X_transformed = pca.transform(X_generated)\n",
    "    plt.scatter(X_transformed[:, 0], X_transformed[:, 1], c=colors[i], label=run)\n",
    "\n",
    "plt.colorbar()\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_generated = []\n",
    "entropies = []\n",
    "clusters = []\n",
    "    \n",
    "pca = PCA(n_components=2).fit(np.concatenate((fps_active_as_array,fps_inactive_as_array)))\n",
    "pca_active = pca.transform(fps_active_as_array)\n",
    "pca_inactive = pca.transform(fps_inactive_as_array)\n",
    "predicted_actives = np.where(clf.predict_proba(ecfp4(smiles_actives))[:, 1]>0.5)[0]\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    curr_fps_generated = fps_generated_as_array[i]\n",
    "    curr_fps_generated_bitv = fps_generated_as_bitv[i]    \n",
    "    pca_generated.append(pca.transform(curr_fps_generated))\n",
    "    if kmeans:\n",
    "        curr_clusters = clustering.predict(curr_fps_generated)  \n",
    "    else:\n",
    "        curr_clusters = [find_cluster(fp, centroids_fp) for fp in curr_fps_generated_bitv]\n",
    "    probs = []\n",
    "    for i in range(len(np.unique(centroids))):\n",
    "        probs.append(len(np.where(np.array(curr_clusters)==i)[0])/len(curr_clusters))\n",
    "    entropy = scipy.stats.entropy(probs)/ np.log(len(curr_clusters))\n",
    "    clusters.append(curr_clusters)\n",
    "    entropies.append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin_ymin = np.amin(np.vstack([np.amin(p, axis=0) for p in pca_generated]), axis=0).tolist()\n",
    "xmax_ymax = np.amax(np.vstack([np.amax(p, axis=0) for p in pca_generated]), axis=0).tolist()\n",
    "x_lims = [xmin_ymin[0]] + [xmax_ymax[0]]\n",
    "y_lims = [xmin_ymin[1]] + [xmax_ymax[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = (20, 20), nrows=max(1, math.ceil(len(runs)/3)) , ncols=3)\n",
    "fig.tight_layout(pad=1.5)\n",
    "no_legend = 0\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    curr_clusters = clusters[i]\n",
    "    entropy = entropies[i]\n",
    "    pca_gen = pca_generated[i]\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.set_title(run.replace('_', ' ') + ': ' + str(entropy)[:4])\n",
    "    ax.set_ylim(y_lims)\n",
    "    ax.set_xlim(x_lims)\n",
    "    ax.scatter(pca_active[:, 0], pca_active[:, 1], c='g', label = 'actives', alpha=0.75)    \n",
    "    for c in np.unique(curr_clusters):\n",
    "        ax.scatter(pca_gen[:, 0][np.where(curr_clusters==c)], pca_gen[:, 1][np.where(curr_clusters==c)], label= 'Cluster ' + str(c), alpha=0.25)    \n",
    "\n",
    "    ax.scatter(pca_active[predicted_actives, 0], pca_active[predicted_actives, 1], c='r', label = 'Predicted actives', alpha=0.75, marker='s')\n",
    "    #ax.scatter(pca_inactive[:, 0], pca_inactive[:, 1], c='r', label = 'inactives', alpha=0.25)\n",
    "    if len(np.unique(curr_clusters)) == np.amax([len(set(c)) for c in clusters]) and  no_legend == 0 :\n",
    "        ax.legend(loc=4)\n",
    "        no_legend = 1\n",
    "fig.suptitle('PCA projections of generated molecules in the training set actives/inactives space\\nHighlighting predicted actives',fontweight =\"bold\", y=1.05)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 25))\n",
    "novel_01 = []\n",
    "titles = []\n",
    "\n",
    "predicted_actives = np.where(clf.predict_proba(ecfp4(smiles_actives))[:, 1]>0.5)[0]\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    curr_fps_generated = fps_generated_as_bitv[i]\n",
    "    n_new = 0\n",
    "    for s in np.array(smiles_actives)[predicted_actives]:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        if max_tanimoto_similarity([AllChem.GetMorganFingerprintAsBitVect(mol, 2)], curr_fps_generated)>0.9:\n",
    "            n_new += 1\n",
    "    novel_01.append(n_new/len(predicted_actives))\n",
    "    titles.append(run.replace('_', ' '))\n",
    "    \n",
    "display_df = pd.DataFrame(zip(titles, novel_01), columns =['Applicability domain', 'Generated structures closer than 0.1 (Tanimoto distance, MFP2 FPs) from test set actives'])\n",
    "chart = sns.catplot(x=\"Applicability domain\", y=\"Generated structures closer than 0.1 (Tanimoto distance, MFP2 FPs) from test set actives\", kind=\"bar\", data=display_df)\n",
    "for axes in chart.axes.flat:\n",
    "    _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=90)\n",
    "plt.title(\"Actives recovered at distance < 0.1\")\n",
    "plt.show()\n",
    "\n",
    "#plt.barh(np.arange(len(novel_01)), novel_01, height = 0.25 , label='fraction of actives recovered at distance < 0.1')\n",
    "#plt.yticks(ticks = np.arange(len(novel_01)), labels = titles, rotation='horizontal')\n",
    "#plt.legend(loc=0)\n",
    "   \n",
    "#fig.suptitle('Fraction of predicted actives in the dataset at distance < 0.1',fontweight =\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "novel_recovered = []\n",
    "titles = []\n",
    "\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    smiles_generated = smiles_list[i]\n",
    "    fps_generated = []\n",
    "    for s in smiles_generated:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        fps_generated.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2))\n",
    "    n_new = 0\n",
    "    for s in np.array(smiles_actives)[predicted_actives]:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        if max_tanimoto_similarity([AllChem.GetMorganFingerprintAsBitVect(mol, 2)], fps_generated)>0.99:\n",
    "            n_new += 1\n",
    "    novel_recovered.append(n_new/len(predicted_actives))\n",
    "    titles.append(run.replace('_', ' '))\n",
    "display_df = pd.DataFrame(zip(titles, novel_recovered), columns =['Applicability domain', 'Generated structures with similarity=1 (same structure, stereoisomer or very close structure) from test set actives'])\n",
    "chart = sns.catplot(y=\"Applicability domain\", x=\"Generated structures with similarity=1 (same structure, stereoisomer or very close structure) from test set actives\", kind=\"bar\", data=display_df)\n",
    "for axes in chart.axes.flat:\n",
    "    _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=90)\n",
    "plt.title(\"Actives recovered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qed_dataset = []\n",
    "sas_dataset = []\n",
    "for s in smiles_actives + smiles_inactives:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    qed_dataset.append(Descriptors.qed(mol))\n",
    "    sas_dataset.append(calculateScore(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QED = []\n",
    "SAS = []\n",
    "\n",
    "SAS_for_results = []\n",
    "QED_for_results = []\n",
    "ad = []\n",
    "for i, run in enumerate(runs):\n",
    "    avg_sims = []\n",
    "    max_sim = []\n",
    "    smiles_generated = smiles_list[i]\n",
    "    qed_generated = []\n",
    "    sas_generated = []\n",
    "    for s in smiles_generated:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        qed_generated.append(Descriptors.qed(mol))\n",
    "        sas_generated.append(calculateScore(mol))\n",
    "\n",
    "    \n",
    "        \n",
    "        QED.append(Descriptors.qed(mol))\n",
    "        SAS.append(calculateScore(mol))\n",
    "        ad.append(run)\n",
    "    SAS_for_results.append(sas_generated)\n",
    "    QED_for_results.append(qed_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize= (15, 15))\n",
    "#display_df = pd.DataFrame(zip(ad, QED), columns =['Applicability domain', 'QED'])\n",
    "#chart = sns.boxplot(y=\"Applicability domain\", x=\"QED\", data=display_df)\n",
    "#['$' + str(x) + '$' for x in runs]\n",
    "c = 'blue'\n",
    "box = plt.boxplot(SAS_for_results, labels = [x.replace('_', ' ') for x in runs], vert=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c, color=c, alpha=0.5),\n",
    "            capprops=dict(color=c),\n",
    "            whiskerprops=dict(color='k'),\n",
    "            flierprops=dict(color=c, markeredgecolor=c),\n",
    "            medianprops=dict(color='k'),)\n",
    "\n",
    "\n",
    "\n",
    "#plt.boxplot(QED, vert=False)\n",
    "#plt.yticks(np.arange(len(runs)) + 1, labels=runs, rotation='horizontal')\n",
    "plt.axvline(np.percentile(sas_dataset, 100), ls='--', label='Dataset extreme QED values', c='g')\n",
    "plt.axvline(np.percentile(sas_dataset, 0), ls='--', c='g')\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.fill_between([np.percentile(sas_dataset, 0), np.percentile(sas_dataset, 100)], ymin, ymax, color='g', alpha=0.1, label = 'Valid QED')\n",
    "#plt.legend(loc=4)\n",
    "plt.xlabel(\"Synthetic Accessibility Score Distribution\")\n",
    "#plt.ylabel(\"Applicability domain\")\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/JAK2/SAS_distribution.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15, 15))\n",
    "#display_df = pd.DataFrame(zip(ad, QED), columns =['Applicability domain', 'QED'])\n",
    "#chart = sns.boxplot(y=\"Applicability domain\", x=\"QED\", data=display_df)\n",
    "#['$' + str(x) + '$' for x in runs]\n",
    "c = 'blue'\n",
    "box = plt.boxplot(QED_for_results, labels = [x.replace('_', ' ') for x in runs], vert=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c, color=c, alpha=0.5),\n",
    "            capprops=dict(color=c),\n",
    "            whiskerprops=dict(color='k'),\n",
    "            flierprops=dict(color=c, markeredgecolor=c),\n",
    "            medianprops=dict(color='k'),)\n",
    "\n",
    "\n",
    "\n",
    "#plt.boxplot(QED, vert=False)\n",
    "#plt.yticks(np.arange(len(runs)) + 1, labels=runs, rotation='horizontal')\n",
    "plt.axvline(np.percentile(qed_dataset, 100), ls='--', label='Dataset extreme QED values', c='g')\n",
    "plt.axvline(np.percentile(qed_dataset, 0), ls='--', c='g')\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.fill_between([np.percentile(qed_dataset, 0), np.percentile(qed_dataset, 100)], ymin, ymax, color='g', alpha=0.1, label = 'Valid QED')\n",
    "#plt.legend(loc=4)\n",
    "plt.xlabel(\"QED Distribution\")\n",
    "#plt.ylabel(\"Applicability domain\")\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/JAK2/QED_distribution.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different AD's outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import qualitative_analysis, return_distribution_cycle_size, return_distribution_mw, return_distribution_halogen, return_distribution_heteroatoms, return_distribution_radicals, return_distribution_sulphur, qualitative_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_similarities = []\n",
    "max_similarities = []\n",
    "common_molecules = {}\n",
    "for i, run in enumerate(runs):\n",
    "    avg_sims = []\n",
    "    max_sim = []\n",
    "    smiles_generated = smiles_list[i]\n",
    "    fps_generated = fps_generated_as_bitv[i]\n",
    "    for j, comparison_run in enumerate(runs):\n",
    "        smiles_generated = smiles_list[j]\n",
    "        fps_other = fps_generated_as_bitv[j]\n",
    "        if j<i:\n",
    "            indexes, indexes_other = indexes_identical_fps(fps_generated, fps_other)\n",
    "            common_molecules[run + '_vs_' + comparison_run] = [indexes, indexes_other] \n",
    "        avg_sims.append(average_tanimoto_similarity(fps_generated, fps_other))\n",
    "        max_sim.append(max_tanimoto_similarity(fps_generated, fps_other))\n",
    "    average_similarities.append(avg_sims)\n",
    "    max_similarities.append(max_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "labels = runs\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 20), nrows=1 , ncols=1)\n",
    "\n",
    "fig.tight_layout(pad=1.5)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title(\"Average similarities between generated sets\")\n",
    "\n",
    "im = ax.imshow(np.array(average_similarities), cmap='Blues')\n",
    "ax.set_yticks(ticks=range(len(runs)))\n",
    "ax.set_xticks(ticks=range(len(runs)))\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.set_yticklabels(labels, rotation=45)\n",
    "ax.tick_params(axis='both', which='major')\n",
    "ax.tick_params(axis='both', which='minor')\n",
    "#plt.colorbar()\n",
    "fig.tight_layout(pad=3.0)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/JAK2/similarities.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = (20, 20), nrows=max(1, math.ceil(len(runs)/3)) , ncols=3, sharey=True)\n",
    "\n",
    "fig.tight_layout(pad=1.5)\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.set_title(run.replace('_', ' '))\n",
    "    scores = np.array(scores_trajectories[runs.index(run)])\n",
    "    \"\"\"\n",
    "    median = np.median(scores, 1)\n",
    "    q25 = np.percentile(scores, 5, axis=1)\n",
    "    q75 = np.percentile(scores, 95, axis=1)\n",
    "    ax.plot(median, c='b', label='Generated scores')\n",
    "    ax.fill_between(\n",
    "        np.arange(median.shape[0]), q25, q75, alpha=.1, color='b')\n",
    "    \"\"\"\n",
    "    ax.plot(scores, c='b', label='Generated scores')\n",
    "    ax.axhline(y=0.5, linewidth=1, ls='--', color='r', label='Predicted active threshold')\n",
    "    ax.axhline(y=np.max(scores_test), linewidth=1, ls='--', color='g', label='Maximum test set score')\n",
    "    ax.legend(loc=4)\n",
    "fig.suptitle('Evolution of scores distributions', fontweight =\"bold\", y=1.05)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "optimisation_scores = []\n",
    "joint_scores = []\n",
    "logp_scores = []\n",
    "cvars = []\n",
    "at_least_one = []\n",
    "\n",
    "current_joint_scores = []\n",
    "current_logp_scores = []\n",
    "current_cvars = []\n",
    "current_at_least_one = []\n",
    "\n",
    "beta_list = []\n",
    "lcorr_list = []\n",
    "n_smiles_list = []\n",
    "\n",
    "for seed in range(50):\n",
    "    np.random.seed(seed)\n",
    "    \"\"\"\n",
    "    length = np.random.uniform(1, 2)\n",
    "    \n",
    "    threshold_low_clogp_random = np.random.uniform(0, 5)\n",
    "    threshold_low_clogp = random.choice([threshold_low_clogp_random, 7])\n",
    "    threshold_low_clogp = random.choice(logp_test) -length/2\n",
    "    threshold_high_clogp = threshold_low_clogp + length/2\n",
    "    \n",
    "\n",
    "    length = np.random.uniform(10, 15)\n",
    "    threshold_low_tpsa_random = np.random.uniform(70, 130)\n",
    "    threshold_low_tpsa = threshold_low_tpsa_random\n",
    "    #threshold_low_tpsa = random.choice([threshold_low_tpsa_random, threshold_low_tpsa_random, 140])\n",
    "    #threshold_low_tpsa = np.random.uniform(70, 130)\n",
    "    threshold_high_tpsa = threshold_low_tpsa + length\n",
    "    \"\"\"\n",
    "    cluster = random.choice(range(5))\n",
    "    mw_threshold = random.choice([550, 650])\n",
    "    criteria = \"clogp\"\n",
    "    \n",
    "    \"\"\"\n",
    "    smiles_valid = np.random.choice(smiles_test, 100)\n",
    "    fp_valid = []\n",
    "    for s in smiles_valid:\n",
    "        fp_valid.append(AllChem.GetMorganFingerprintAsBitVect(mol, 2))\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    #smiles_generated = np.random.choice(smiles_augmented, 3000)\n",
    "    ground_truth = []\n",
    "    smiles_generated = smiles_list[j]\n",
    "    for s in smiles_generated:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        fp = ecfp4([s])[0].reshape(1, -1)\n",
    "        prediction = clf.predict_proba(fp)[0, 1]\n",
    "        #prediction = np.random.binomial(prediction, 1)\n",
    "        ground_truth.append(prediction)\n",
    "    \"\"\"    \n",
    "    for j, directory in enumerate(runs):\n",
    "        smiles_generated = smiles_list[j]\n",
    "        scores_generated = scores_list[j]\n",
    "        for lcorr in [0.5]:\n",
    "            for n_smiles in [1, 10, 100]:\n",
    "                for seed_other in range(10):\n",
    "                    np.random.seed(seed_other)\n",
    "\n",
    "                    betas = [0, 1, 10, 100, 1000]\n",
    "                    beta = round(betas[j], 2)\n",
    "                    lcorr = round(lcorr, 2)\n",
    "\n",
    "                    solutions_risk_adverse = random.sample(smiles_generated, n_smiles)\n",
    "                    current_optimisation_score = []\n",
    "                    \n",
    "                    n_smiles_list.append(n_smiles)\n",
    "                    beta_list.append(beta)\n",
    "                    lcorr_list.append(lcorr)\n",
    "\n",
    "\n",
    "                    scores = [] \n",
    "                    scores_additional = []\n",
    "                    scores_prediction = []\n",
    "                    for s in solutions_risk_adverse:\n",
    "                        mol = Chem.MolFromSmiles(s)\n",
    "                        fp = ecfp4([s])[0].reshape(1, -1)\n",
    "                        prediction = clf.predict_proba(fp)[0, 1]\n",
    "                        prediction = np.random.binomial(1, prediction)\n",
    "                        fp = np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)).reshape(1, -1)\n",
    "                        additional = 1 * clustering.predict(fp)[0]==cluster\n",
    "                        scores_additional.append(additional)\n",
    "                        scores.append(additional*prediction) \n",
    "                        \n",
    "                        scores_prediction.append(prediction)\n",
    "                    if np.sum(scores)==0:\n",
    "                        at_least_one.append(0)\n",
    "                    else:\n",
    "                        at_least_one.append(1)\n",
    "                    optimisation_scores.append(np.mean(scores_prediction))\n",
    "                    logp_scores.append(np.mean(scores_additional))\n",
    "                    joint_scores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = pd.DataFrame(zip(joint_scores, logp_scores, optimisation_scores,  at_least_one, lcorr_list, beta_list, n_smiles_list), columns =['Average score', 'Additional score', 'Optimization score', 'At least one', \"Length of correlation\", 'Beta', 'N'])\n",
    "plt.title(\"At least one molecule according to selection parameters\")\n",
    "pivoted = display_df.groupby([\"Beta\", \"N\"]).mean().reset_index().pivot(\"N\", \"Beta\", \"At least one\")\n",
    "sns.heatmap(pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logps = []\n",
    "\n",
    "for l in smiles_list:\n",
    "    current_logp = []\n",
    "    for s in l:\n",
    "        fp = ecfp4([s])[0].reshape(1, -1)\n",
    "        current_logp.append(MolLogP(Chem.MolFromSmiles(s)))\n",
    "    logps.append(current_logp)\n",
    "    \n",
    "logp_test = []\n",
    "for s in np.array(smiles_actives + smiles_inactives):\n",
    "    fp = ecfp4([s])[0].reshape(1, -1)\n",
    "    logp_test.append(MolLogP(Chem.MolFromSmiles(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpsa_test = []\n",
    "for s in np.array(smiles_actives + smiles_inactives):\n",
    "    tpsa_test.append(CalcTPSA(Chem.MolFromSmiles(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(smiles, criteria=\"mw\", threshold_low_clogp=0, threshold_high_clogp=2, threshold_low_tpsa=50, threshold_high_tpsa=70, mw_threshold=350):\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    logp = MolLogP(mol)>=threshold_low_clogp and MolLogP(mol)<=threshold_high_clogp\n",
    "    tpsa = CalcTPSA(mol)>=threshold_low_tpsa and CalcTPSA(mol)<=threshold_high_tpsa\n",
    "    mw = ExactMolWt(mol)<mw_threshold\n",
    "    #return logp * tpsa\n",
    "    if criteria==\"mw\":\n",
    "        return mw\n",
    "    elif criteria== \"clogp\":\n",
    "        return logp\n",
    "    else:\n",
    "        return tpsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "optimisation_scores = []\n",
    "joint_scores = []\n",
    "logp_scores = []\n",
    "cvars = []\n",
    "at_least_one = []\n",
    "\n",
    "current_joint_scores = []\n",
    "current_logp_scores = []\n",
    "current_cvars = []\n",
    "current_at_least_one = []\n",
    "\n",
    "beta_list = []\n",
    "lcorr_list = []\n",
    "n_smiles_list = []\n",
    "\n",
    "for seed in range(50):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    length = np.random.uniform(1, 2)\n",
    "    \n",
    "    threshold_low_clogp_random = np.random.uniform(0, 5)\n",
    "    threshold_low_clogp = random.choice([threshold_low_clogp_random, 7])\n",
    "    threshold_low_clogp = random.choice(logp_test) - length/2\n",
    "    threshold_high_clogp = threshold_low_clogp + length/2\n",
    "    \n",
    "\n",
    "    length = np.random.uniform(10, 15)\n",
    "    threshold_low_tpsa_random = np.random.uniform(70, 130)\n",
    "    threshold_low_tpsa = threshold_low_tpsa_random\n",
    "    #threshold_low_tpsa = random.choice([threshold_low_tpsa_random, threshold_low_tpsa_random, 140])\n",
    "    #threshold_low_tpsa = np.random.uniform(70, 130)\n",
    "    threshold_high_tpsa = threshold_low_tpsa + length\n",
    "    \n",
    "    cluster = random.choice(range(5))\n",
    "    mw_threshold = random.choice([550, 650])\n",
    "    criteria = \"clogp\"\n",
    "    \n",
    "    for j, directory in enumerate(runs):\n",
    "        smiles_generated = smiles_list[j]\n",
    "        scores_generated = scores_list[j]\n",
    "        for lcorr in [0.5]:\n",
    "            for n_smiles in [1, 10, 100]:\n",
    "                for seed_other in range(10):\n",
    "                    np.random.seed(seed_other)\n",
    "\n",
    "                    betas = [0, 1, 10, 100, 1000]\n",
    "                    beta = round(betas[j], 2)\n",
    "                    lcorr = round(lcorr, 2)\n",
    "\n",
    "                    solutions_risk_adverse = random.sample(smiles_generated, n_smiles)\n",
    "                    current_optimisation_score = []\n",
    "                    \n",
    "                    n_smiles_list.append(n_smiles)\n",
    "                    beta_list.append(beta)\n",
    "                    lcorr_list.append(lcorr)\n",
    "\n",
    "\n",
    "                    scores = [] \n",
    "                    scores_additional = []\n",
    "                    scores_prediction = []\n",
    "                    for s in solutions_risk_adverse:\n",
    "                        mol = Chem.MolFromSmiles(s)\n",
    "                        fp = ecfp4([s])[0].reshape(1, -1)\n",
    "                        prediction = clf.predict_proba(fp)[0, 1]\n",
    "                        prediction = np.random.binomial(1, prediction)\n",
    "                        fp = np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)).reshape(1, -1)\n",
    "      \n",
    "                        scores_additional.append(is_valid(s, \"clogp\", threshold_low_clogp, threshold_high_clogp, threshold_low_tpsa, threshold_high_tpsa, mw_threshold))\n",
    "                        scores.append(is_valid(s, \"clogp\", threshold_low_clogp, threshold_high_clogp, threshold_low_tpsa, threshold_high_tpsa, mw_threshold)*prediction) \n",
    "     \n",
    "                        scores_prediction.append(prediction)\n",
    "                    if np.sum(scores)==0:\n",
    "                        at_least_one.append(0)\n",
    "                    else:\n",
    "                        at_least_one.append(1)\n",
    "                    optimisation_scores.append(np.mean(scores_prediction))\n",
    "                    logp_scores.append(np.mean(scores_additional))\n",
    "                    joint_scores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = pd.DataFrame(zip(joint_scores, logp_scores, optimisation_scores,  at_least_one, lcorr_list, beta_list, n_smiles_list), columns =['Average score', 'Additional score', 'Optimization score', 'At least one', \"Length of correlation\", 'Beta', 'N'])\n",
    "plt.title(\"At least one molecule according to selection parameters\")\n",
    "pivoted = display_df.groupby([\"Beta\", \"N\"]).mean().reset_index().pivot(\"N\", \"Beta\", \"At least one\")\n",
    "sns.heatmap(pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimisation_scores = []\n",
    "joint_scores = []\n",
    "logp_scores = []\n",
    "cvars = []\n",
    "at_least_one = []\n",
    "\n",
    "current_joint_scores = []\n",
    "current_logp_scores = []\n",
    "current_cvars = []\n",
    "current_at_least_one = []\n",
    "\n",
    "beta_list = []\n",
    "lcorr_list = []\n",
    "n_smiles_list = []\n",
    "\n",
    "for seed in range(50):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    length = np.random.uniform(1, 2)\n",
    "    threshold_low_clogp_random = np.random.uniform(0, 5)\n",
    "    threshold_low_clogp = random.choice([threshold_low_clogp_random, 7])\n",
    "    threshold_low_clogp = random.choice(logp_test) -length/2\n",
    "    threshold_high_clogp = threshold_low_clogp + length/2\n",
    "    \n",
    "\n",
    "    length = np.random.uniform(5, 10)\n",
    "    threshold_low_tpsa_random = np.random.uniform(70, 130)\n",
    "    threshold_low_tpsa = random.choice(tpsa_test) -length/2\n",
    "    threshold_high_tpsa = threshold_low_clogp + length/2\n",
    "    \n",
    "    cluster = random.choice(range(5))\n",
    "    mw_threshold = random.choice([550, 650])\n",
    "    criteria = \"clogp\"\n",
    "\n",
    "    for j, directory in enumerate(runs):\n",
    "        smiles_generated = smiles_list[j]\n",
    "        scores_generated = scores_list[j]\n",
    "        for lcorr in [0.5]:\n",
    "            for n_smiles in [1, 10, 100]:\n",
    "                for seed_other in range(10):\n",
    "                    np.random.seed(seed_other)\n",
    "\n",
    "                    betas = [0, 1, 10, 100, 1000]\n",
    "                    beta = round(betas[j], 2)\n",
    "                    lcorr = round(lcorr, 2)\n",
    "\n",
    "                    solutions_risk_adverse = random.sample(smiles_generated, n_smiles)\n",
    "                    current_optimisation_score = []\n",
    "                    \n",
    "                    n_smiles_list.append(n_smiles)\n",
    "                    beta_list.append(beta)\n",
    "                    lcorr_list.append(lcorr)\n",
    "\n",
    "\n",
    "                    scores = [] \n",
    "                    scores_additional = []\n",
    "                    scores_prediction = []\n",
    "                    for s in solutions_risk_adverse:\n",
    "                        mol = Chem.MolFromSmiles(s)\n",
    "                        fp = ecfp4([s])[0].reshape(1, -1)\n",
    "                        prediction = clf.predict_proba(fp)[0, 1]\n",
    "                        prediction = np.random.binomial(1, prediction)\n",
    "                        fp = np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2)).reshape(1, -1)\n",
    "             \n",
    "                        scores_additional.append(is_valid(s, \"tpsa\", threshold_low_clogp, threshold_high_clogp, threshold_low_tpsa, threshold_high_tpsa, mw_threshold))\n",
    "                        scores.append(is_valid(s, \"tpsa\", threshold_low_clogp, threshold_high_clogp, threshold_low_tpsa, threshold_high_tpsa, mw_threshold)*prediction) \n",
    "                \n",
    "                        \n",
    "                        scores_prediction.append(prediction)\n",
    "                    if np.sum(scores)==0:\n",
    "                        at_least_one.append(0)\n",
    "                    else:\n",
    "                        at_least_one.append(1)\n",
    "                    optimisation_scores.append(np.mean(scores_prediction))\n",
    "                    logp_scores.append(np.mean(scores_additional))\n",
    "                    joint_scores.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = pd.DataFrame(zip(joint_scores, logp_scores, optimisation_scores,  at_least_one, lcorr_list, beta_list, n_smiles_list), columns =['Average score', 'Additional score', 'Optimization score', 'At least one', \"Length of correlation\", 'Beta', 'N'])\n",
    "plt.title(\"At least one molecule according to selection parameters\")\n",
    "pivoted = display_df.groupby([\"Beta\", \"N\"]).mean().reset_index().pivot(\"N\", \"Beta\", \"At least one\")\n",
    "sns.heatmap(pivoted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
